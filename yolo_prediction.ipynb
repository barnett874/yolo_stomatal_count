{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d92b015",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv5SlidingWindowDetector:\n",
    "    def __init__(self, model_path, device='cuda'):\n",
    "        self.device = device\n",
    "        self.model = torch.hub.load('ultralytics/yolov5', 'custom', path=model_path)\n",
    "        self.model.to(self.device).eval()\n",
    "        self.class_names = self.model.names\n",
    "\n",
    "    def detect(\n",
    "        self,\n",
    "        image_path,\n",
    "        crop_size=640,\n",
    "        stride=512,\n",
    "        conf_thres=0.25,\n",
    "        iou_thres=0.45,\n",
    "        min_box_size=10,  # ‚úÖ Êñ∞Â¢ûÂèÇÊï∞\n",
    "        save_result=True,\n",
    "        save_img_path='detection_result.jpg',\n",
    "        save_txt_path='detection_result.txt'\n",
    "    ):\n",
    "        orig_img = cv2.imread(str(image_path))\n",
    "        if orig_img is None:\n",
    "            raise FileNotFoundError(f\"Cannot read image: {image_path}\")\n",
    "        H, W = orig_img.shape[:2]\n",
    "\n",
    "        pad_H = (crop_size - H % crop_size) % crop_size\n",
    "        pad_W = (crop_size - W % crop_size) % crop_size\n",
    "        img = cv2.copyMakeBorder(orig_img, 0, pad_H, 0, pad_W, cv2.BORDER_CONSTANT, value=0)\n",
    "        padded_H, padded_W = img.shape[:2]\n",
    "\n",
    "        all_boxes, all_scores, all_classes = [], [], []\n",
    "\n",
    "        for y in tqdm(range(0, padded_H - crop_size + 1, stride)):\n",
    "            for x in range(0, padded_W - crop_size + 1, stride):\n",
    "                crop = img[y:y+crop_size, x:x+crop_size]\n",
    "                results = self.model(crop)\n",
    "                for *xyxy, conf, cls in results.xyxy[0].cpu().numpy():\n",
    "                    if conf < conf_thres:\n",
    "                        continue\n",
    "                    x1, y1, x2, y2 = xyxy\n",
    "                    abs_x1 = x1 + x\n",
    "                    abs_y1 = y1 + y\n",
    "                    abs_x2 = x2 + x\n",
    "                    abs_y2 = y2 + y\n",
    "                    box_w = abs_x2 - abs_x1\n",
    "                    box_h = abs_y2 - abs_y1\n",
    "\n",
    "                    if box_w < min_box_size or box_h < min_box_size:\n",
    "                        continue  # ‚úÖ ÂøΩÁï•ËøáÂ∞èÊ°Ü\n",
    "\n",
    "                    all_boxes.append([abs_x1, abs_y1, abs_x2, abs_y2])\n",
    "                    all_scores.append(conf)\n",
    "                    all_classes.append(int(cls))\n",
    "\n",
    "        if not all_boxes:\n",
    "            print(\"‚ö†Ô∏è No valid objects detected.\")\n",
    "            return\n",
    "\n",
    "        boxes_tensor = torch.tensor(all_boxes)\n",
    "        scores_tensor = torch.tensor(all_scores)\n",
    "        keep = nms(boxes_tensor, scores_tensor, iou_thres)\n",
    "\n",
    "        boxes_tensor = boxes_tensor[keep]\n",
    "        scores_tensor = scores_tensor[keep]\n",
    "        classes_tensor = torch.tensor(all_classes)[keep]\n",
    "\n",
    "        result_img = orig_img.copy()\n",
    "        yolo_labels = []\n",
    "\n",
    "        for box, score, cls_id in zip(boxes_tensor, scores_tensor, classes_tensor):\n",
    "            x1, y1, x2, y2 = map(int, box.tolist())\n",
    "            cv2.rectangle(result_img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # YOLO Ê†ºÂºèÂΩí‰∏ÄÂåñÊ†áÁ≠æ\n",
    "            cx = (x1 + x2) / 2 / W\n",
    "            cy = (y1 + y2) / 2 / H\n",
    "            bw = (x2 - x1) / W\n",
    "            bh = (y2 - y1) / H\n",
    "            yolo_labels.append(f\"{int(cls_id)} {cx:.6f} {cy:.6f} {bw:.6f} {bh:.6f}\")\n",
    "\n",
    "        if save_result:\n",
    "            cv2.imwrite(save_img_path, result_img)\n",
    "            with open(save_txt_path, 'w') as f:\n",
    "                f.write('\\n'.join(yolo_labels))\n",
    "            print(f\"‚úÖ Saved detection result to {save_img_path}\")\n",
    "            print(f\"‚úÖ Saved YOLO label to {save_txt_path}\")\n",
    "        else:\n",
    "            return result_img, yolo_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e851b161",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "detector = YOLOv5SlidingWindowDetector(model_path='yolov5/run/train/stomata_yolov5x2/weights/best.pt')\n",
    "\n",
    "detector.detect(\n",
    "    image_path='Êµ∑ÂçóË£ÅÂâ™/47 (2).jpg',\n",
    "    crop_size=640,\n",
    "    stride=128,\n",
    "    conf_thres=0.25,\n",
    "    iou_thres=0.15,\n",
    "    save_result=True,\n",
    "    save_img_path='test.jpg',\n",
    "    save_txt_path='test.txt', \n",
    "    min_box_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f76bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "def batch_detect_from_folder(\n",
    "    detector, \n",
    "    input_folder, \n",
    "    output_folder='outputs', \n",
    "    crop_size=640,\n",
    "    stride=512,\n",
    "    conf_thres=0.25,\n",
    "    iou_thres=0.45,\n",
    "    min_box_size=10\n",
    "):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    image_paths = glob(os.path.join(input_folder, '*.[jp][pn]g'))  # ÊîØÊåÅjpg„ÄÅjpeg„ÄÅpng\n",
    "    print(f\"üìÇ Found {len(image_paths)} images in {input_folder}\")\n",
    "\n",
    "    for img_path in image_paths:\n",
    "        filename = Path(img_path).stem\n",
    "        save_img_path = os.path.join(output_folder, f'{filename}_det.jpg')\n",
    "        save_txt_path = os.path.join(output_folder, f'{filename}.txt')\n",
    "        \n",
    "        print(f\"üîç Processing {img_path}...\")\n",
    "        detector.detect(\n",
    "            image_path=img_path,\n",
    "            crop_size=crop_size,\n",
    "            stride=stride,\n",
    "            conf_thres=conf_thres,\n",
    "            iou_thres=iou_thres,\n",
    "            min_box_size=min_box_size,\n",
    "            save_result=True,\n",
    "            save_img_path=save_img_path,\n",
    "            save_txt_path=save_txt_path\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f53d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YOLOv5SlidingWindowDetector(model_path='yolov5/run/train/stomata_yolov5x2/weights/best.pt')\n",
    "\n",
    "\n",
    "batch_detect_from_folder(\n",
    "    detector,\n",
    "    input_folder='Êµ∑ÂçóË£ÅÂâ™',      # ËæìÂÖ•ÂõæÂÉèÊñá‰ª∂Â§πË∑ØÂæÑ\n",
    "    output_folder='Êµ∑ÂçóÈ¢ÑÊµã',    # ËæìÂá∫Êñá‰ª∂Â§π\n",
    "    crop_size=640,\n",
    "    stride=128,\n",
    "    conf_thres=0.25,\n",
    "    iou_thres=0.15,\n",
    "    min_box_size=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158b0ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YOLOv5SlidingWindowDetector(model_path='yolov5/run/train/stomata_yolov5x2/weights/best.pt')\n",
    "\n",
    "\n",
    "batch_detect_from_folder(\n",
    "    detector,\n",
    "    input_folder='Ê≤≥ÂçóËá™‰∫§Á≥ªÁ©ó‰ΩçÂè∂',      # ËæìÂÖ•ÂõæÂÉèÊñá‰ª∂Â§πË∑ØÂæÑ\n",
    "    output_folder='Ê≤≥ÂçóÈ¢ÑÊµã',    # ËæìÂá∫Êñá‰ª∂Â§π\n",
    "    crop_size=640,\n",
    "    stride=128,\n",
    "    conf_thres=0.25,\n",
    "    iou_thres=0.15,\n",
    "    min_box_size=20\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
